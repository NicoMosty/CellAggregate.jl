{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_force!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../../src/struct_data.jl\")\n",
    "include(\"../../src/neighbor.jl\")\n",
    "include(\"../../src/forces/forces.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000013 seconds (5 allocations: 208 bytes)\n",
      "ModelSet\n",
      "  Time: TimeModel\n",
      "    tₛᵢₘ: Float64 150000.0\n",
      "    dt: Float64 0.5\n",
      "    nₖₙₙ: Int64 100\n",
      "    nₛₐᵥₑ: Int64 50\n",
      "  Input: InputModel\n",
      "    outer_ratio: Float64 0.8\n",
      "    path_input: String \"../../data/init/Sphere\"\n",
      "  Output: OutputModel\n",
      "    name_output: String \"Test_1\"\n",
      "    path_output: String \"\"\n"
     ]
    }
   ],
   "source": [
    "@time model = ModelSet(\n",
    "    TimeModel(\n",
    "        tₛᵢₘ  = 150000.0,\n",
    "        dt    = 0.5,\n",
    "        nₖₙₙ  = 100,\n",
    "        nₛₐᵥₑ = 50\n",
    "    ),\n",
    "    InputModel(\n",
    "        outer_ratio = 0.8,\n",
    "        path_input  = \"../../data/init/Sphere\"\n",
    "    ),\n",
    "    OutputModel(\n",
    "        name_output = \"Test_1\",\n",
    "        path_output = \"\"\n",
    "    ) \n",
    ")\n",
    "\n",
    "dump(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.427463 seconds (7.62 M allocations: 837.354 MiB, 4.54% gc time)\n",
      "========================= Type =======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{AggType}:\n",
       " AggType(\"HEK_1\", InteractionPar(Cubic{Float64}(0.01, 2.0, 3.0), ContractilePar(0.001)), 15.27f0, Float32[-1.5 -4.62 -13.88; 0.5 -4.62 -13.88; … ; 0.5 4.62 13.88; 2.5 4.62 13.88], CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})\n",
       " AggType(\"HEK_2\", InteractionPar(Cubic{Float64}(0.01, 2.0, 3.0), ContractilePar(0.001)), 15.27f0, Float32[-1.5 -4.62 -13.88; 0.5 -4.62 -13.88; … ; 0.5 4.62 13.88; 2.5 4.62 13.88], CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================   Index =======================\n",
      "Index of List of Aggregates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×5008 CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  …  2  2  2  2  2  2  2  2  2  2  2  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Number of Aggregates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×5008 CuArray{Int64, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  …  2  2  2  2  2  2  2  2  2  2  2  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Name of Aggregates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×5008 Matrix{String}:\n",
       " \"HEK_1\"  \"HEK_1\"  \"HEK_1\"  \"HEK_1\"  …  \"HEK_2\"  \"HEK_2\"  \"HEK_2\"  \"HEK_2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Position =====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5008×3 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -16.77  -4.62  -13.88\n",
       " -14.77  -4.62  -13.88\n",
       " -12.77  -4.62  -13.88\n",
       " -19.77  -2.89  -13.88\n",
       " -17.77  -2.89  -13.88\n",
       " -15.77  -2.89  -13.88\n",
       " -13.77  -2.89  -13.88\n",
       " -11.77  -2.89  -13.88\n",
       " -20.77  -1.15  -13.88\n",
       " -18.77  -1.15  -13.88\n",
       " -16.77  -1.15  -13.88\n",
       " -14.77  -1.15  -13.88\n",
       " -12.77  -1.15  -13.88\n",
       "   ⋮            \n",
       "  13.77   1.15   13.88\n",
       "  15.77   1.15   13.88\n",
       "  17.77   1.15   13.88\n",
       "  19.77   1.15   13.88\n",
       "  10.77   2.89   13.88\n",
       "  12.77   2.89   13.88\n",
       "  14.77   2.89   13.88\n",
       "  16.77   2.89   13.88\n",
       "  18.77   2.89   13.88\n",
       "  13.77   4.62   13.88\n",
       "  15.77   4.62   13.88\n",
       "  17.77   4.62   13.88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== Geometry ===================\n",
      "Radius_agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×5008 Matrix{Float32}:\n",
       " 15.27  15.27  15.27  15.27  15.27  …  15.27  15.27  15.27  15.27  15.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×5008 Matrix{Int64}:\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  1  1  1  1  1  1  1  1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer/Total = 1.536741214057508\n",
      "====================== Simulation ===================\n",
      "---------------------- Parameter --------------------\n",
      "Force\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cubic{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}(Float32[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], Float32[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0  …  2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Float32[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0  …  3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contractile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContractilePar(Float32[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001  …  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 15.27\n",
       " 15.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Neighbors Size -------------------\n",
      "idx      = (5008, 5008)\n",
      "idx_red  = (1000, 5008)\n",
      "idx_sum  = (1, 5008)\n",
      "idx_cont = (100, 5008)\n",
      "------------------- Forces Size ---------------------\n",
      "dX       = (5008, 3)\n",
      "F        = (5008, 3)\n"
     ]
    }
   ],
   "source": [
    "agg = nothing\n",
    "# @time @start_agg FusionAGG = FusionAggregate(\n",
    "@time agg = FusionAggregate(\n",
    "    [\n",
    "        AggType(\n",
    "            \"HEK_1\", \n",
    "            InteractionPar(\n",
    "                Cubic(0.01,2.0,3.0), \n",
    "                ContractilePar(0.001)\n",
    "            ),\n",
    "            Float64.(readdlm(\"../../data/init/Sphere/15.0.xyz\")[3:end,2:end]) |> cu\n",
    "        ),\n",
    "        AggType(\n",
    "            \"HEK_2\", \n",
    "            InteractionPar(\n",
    "                Cubic(0.01,2.0,3.0), \n",
    "                ContractilePar(0.001)\n",
    "            ),\n",
    "            Float64.(readdlm(\"../../data/init/Sphere/15.0.xyz\")[3:end,2:end]) |> cu\n",
    "        )\n",
    "    ], \n",
    "    model\n",
    ")\n",
    "show_aggregates(agg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ SIZE ------------------------\n",
      "------------------------ IDX -------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×5008 CuArray{Int32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 36  37  38  41  42  43  44  45  57  …  4965  4966  4967  4972  4973  4974\n",
       "  6   7   8  49   1   2   3   3  58     5006  5007  5008  5002  5003  5004\n",
       "  5   6   7  50  50   1   2  53  15     5007  5008  4959  5003  5004  5005\n",
       " 42  43  44   5  51  51  52  54  10     4958  4959  4960  4965  4966  4967\n",
       " 43  44  45  10   6  52  53   7  49     4957  4958  5004  4964  4965  4966\n",
       "  2   3   2   9   4   7   8  14   4  …  5002  5003  4999  5007  5006  5007\n",
       " 35   1  37  40  11   5   6  13  66     5004  5005  5000  4973  5008  4975\n",
       " 37  36  39  42  10  12  13  44  50     4997  4998  4966  4971  4972  4973\n",
       " 51  38  53  58  41  11  12  46  48     4998  4999  4968  4957  4974  4959\n",
       "  0  52   0   0  43  42  43  62   0     4964  4965  4951     0  4958     0\n",
       "  0   0   0   0  59  44  45   0   0  …  4966  4967     0     0     0     0\n",
       "  0   0   0   0   0  60  61   0   0     4949  4950     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  ⋮                   ⋮              ⋱                       ⋮        \n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0  …     0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0  …     0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = zeros(size(agg.Simulation.Neighbor.idx_red)) |> cu\n",
    "\n",
    "println(\"------------------------ SIZE ------------------------\")\n",
    "threads=(100)\n",
    "@cuda(\n",
    "    threads=threads,\n",
    "    blocks=cld.(size(agg.Position,1),threads),\n",
    "    dist_kernel!(\n",
    "        agg.Simulation.Neighbor.idx_red,\n",
    "        agg.Simulation.Neighbor.idx_cont,\n",
    "        agg.Simulation.Neighbor.idx_sum,\n",
    "        dist,\n",
    "        agg.Position,\n",
    "        agg.Simulation.Parameter.Force.rₘₐₓ\n",
    "    )\n",
    ")   \n",
    "\n",
    "println(\"------------------------ IDX -------------------------\")\n",
    "display(agg.Simulation.Neighbor.idx_red)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dot_product (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product(a,b,i,j) = a[i,1]*b[j,1] + a[i,2]*b[j,2] + a[i,3]*b[j,3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InvalidIRError: compiling MethodInstance for teso!(::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Int32, 1}, ::CuDeviceMatrix{Int32, 1}) resulted in invalid LLVM IR\n\u001b[31mReason: unsupported call to an unknown function\u001b[39m\u001b[31m (call to jl_f_apply_type)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:801\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [4] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported call to an unknown function\u001b[39m\u001b[31m (call to ijl_new_structv)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:799\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:801\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [5] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to emit_shmem)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to CuDeviceMatrix{Float32, 3})\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:19\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[36m\u001b[1mHint\u001b[22m\u001b[39m\u001b[36m: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl\u001b[39m",
     "output_type": "error",
     "traceback": [
      "InvalidIRError: compiling MethodInstance for teso!(::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Int32, 1}, ::CuDeviceMatrix{Int32, 1}) resulted in invalid LLVM IR\n\u001b[31mReason: unsupported call to an unknown function\u001b[39m\u001b[31m (call to jl_f_apply_type)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:801\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [4] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported call to an unknown function\u001b[39m\u001b[31m (call to ijl_new_structv)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:799\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mVal\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:801\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [5] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to emit_shmem)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:18\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to CuDeviceMatrix{Float32, 3})\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1mCuStaticSharedArray\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:19\u001b[24m\u001b[39m\n [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m~/.julia/packages/CUDA/pCcGc/src/device/intrinsics/\u001b[39m\u001b[90m\u001b[4mmemory_shared.jl:26\u001b[24m\u001b[39m\n [3] \u001b[0m\u001b[1mteso!\u001b[22m\n\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[6]:14\u001b[24m\u001b[39m\n\u001b[36m\u001b[1mHint\u001b[22m\u001b[39m\u001b[36m: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] check_ir(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, args::LLVM.Module)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/validation.jl:149",
      "  [2] macro expansion",
      "    @ ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:411 [inlined]",
      "  [3] macro expansion",
      "    @ ~/.julia/packages/TimerOutputs/RsWnF/src/TimerOutput.jl:253 [inlined]",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:410 [inlined]",
      "  [5] emit_llvm(job::GPUCompiler.CompilerJob; libraries::Bool, toplevel::Bool, optimize::Bool, cleanup::Bool, only_entry::Bool, validate::Bool, ctx::LLVM.ThreadSafeContext)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/utils.jl:89",
      "  [6] codegen(output::Symbol, job::GPUCompiler.CompilerJob; libraries::Bool, toplevel::Bool, optimize::Bool, cleanup::Bool, strip::Bool, validate::Bool, only_entry::Bool, parent_job::Nothing, ctx::LLVM.ThreadSafeContext)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:118",
      "  [7] codegen",
      "    @ ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:92 [inlined]",
      "  [8] compile(target::Symbol, job::GPUCompiler.CompilerJob; libraries::Bool, toplevel::Bool, optimize::Bool, cleanup::Bool, strip::Bool, validate::Bool, only_entry::Bool, ctx::LLVM.ThreadSafeContext)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:88",
      "  [9] compile",
      "    @ ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:79 [inlined]",
      " [10] compile(job::GPUCompiler.CompilerJob, ctx::LLVM.ThreadSafeContext)",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/src/compiler/compilation.jl:125",
      " [11] #1032",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/compilation.jl:120 [inlined]",
      " [12] LLVM.ThreadSafeContext(f::CUDA.var\"#1032#1033\"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}})",
      "    @ LLVM ~/.julia/packages/LLVM/5aiiG/src/executionengine/ts_module.jl:14",
      " [13] JuliaContext",
      "    @ ~/.julia/packages/GPUCompiler/NVLGB/src/driver.jl:35 [inlined]",
      " [14] compile",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/compilation.jl:119 [inlined]",
      " [15] actual_compilation(cache::Dict{Any, Any}, src::Core.MethodInstance, world::UInt64, cfg::GPUCompiler.CompilerConfig{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, compiler::typeof(CUDA.compile), linker::typeof(CUDA.link))",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/execution.jl:125",
      " [16] cached_compilation(cache::Dict{Any, Any}, src::Core.MethodInstance, cfg::GPUCompiler.CompilerConfig{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams}, compiler::Function, linker::Function)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/NVLGB/src/execution.jl:103",
      " [17] macro expansion",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:318 [inlined]",
      " [18] macro expansion",
      "    @ ./lock.jl:267 [inlined]",
      " [19] cufunction(f::typeof(teso!), tt::Type{Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Int32, 1}, CuDeviceMatrix{Int32, 1}}}; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:313",
      " [20] cufunction(f::typeof(teso!), tt::Type{Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Int32, 1}, CuDeviceMatrix{Int32, 1}}})",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:310",
      " [21] top-level scope",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:104"
     ]
    }
   ],
   "source": [
    "points       = copy(agg.Position)\n",
    "\n",
    "idx_sum = agg.Simulation.Neighbor.idx_sum\n",
    "idx     = agg.Simulation.Neighbor.idx_red\n",
    "pol     = agg.Simulation.Force.Pol\n",
    "\n",
    "force   = agg.Simulation.Force.F\n",
    "\n",
    "function teso!(points,force,pol,idx_sum,idx)\n",
    "\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    k = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "\n",
    "    shared = @cuStaticSharedMem(Float32, (size(points,1),3))\n",
    "\n",
    "    if i <= size(points, 1) && k <= size(points, 2)\n",
    "\n",
    "        # Cleaning force\n",
    "        force[i,k] = 0\n",
    "\n",
    "        # # Generating Polarization vector\n",
    "        phi = 2*pi*(2*rand() - 1)\n",
    "\n",
    "        pol[i,3] = 2*rand() - 1\n",
    "        pol[i,1] = sqrt(1-pol[i,3]^2)*cos(phi)\n",
    "        pol[i,2] = sqrt(1-pol[i,3]^2)*sin(phi)\n",
    "\n",
    "        for j=1:idx_sum[i]\n",
    "            dist = euclidean(points,idx[j,i],i)\n",
    "            shared[i,k] = (points[i,k]-points[idx[j,i],k])/dist\n",
    "\n",
    "            # N_j = \n",
    "\n",
    "            force[i,k] = dist\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "\n",
    "end\n",
    "\n",
    "threads=(16,3)\n",
    "@cuda(\n",
    "    threads=threads,\n",
    "    blocks=(cld.(size(points,1)+1,threads[1]),1),\n",
    "    teso!(points,force,pol,idx_sum,idx)\n",
    ")\n",
    "force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function test!(idx,idx_cont,idx_sum,points,force,force_par,cont_par,dt,t_knn,pol_mat)\n",
    "#     # pol_mat\n",
    "#     # Defining Index for kernel\n",
    "#     i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "#     k = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "\n",
    "#     # Limiting data inside matrix\n",
    "#     if i <= size(points, 1) && k <= size(points, 2)\n",
    "\n",
    "#         # Cleaning force\n",
    "#         force[i,k] = 0\n",
    "\n",
    "#         # # Generating Polarization vector\n",
    "#         phi = 2*pi*(2*rand() - 1)\n",
    "\n",
    "#         pol_mat[i,3] = 2*rand() - 1\n",
    "#         pol_mat[i,1] = sqrt(1-pol_mat[i,3]^2)*cos(phi)\n",
    "#         pol_mat[i,2] = sqrt(1-pol_mat[i,3]^2)*sin(phi)\n",
    "\n",
    "#         # Iterate on each row\n",
    "#         # for j=1:size(idx,1)\n",
    "#         for j=1:idx_sum[i]\n",
    "#             # Finding forces\n",
    "#             if idx[j,i] != 0\n",
    "#                 dist = euclidean(points,idx[j,i],i)\n",
    "#                 # if dist < force_par.rₘₐₓ[i]\n",
    "#                 force[i,k] += force_func(force_par,i,dist) * (points[i,k]-points[idx[j,i],k])/dist\n",
    "#                 # end\n",
    "\n",
    "#             end\n",
    "#         end\n",
    "\n",
    "#         points[i,k] = points[i,k] + force[i,k] * dt\n",
    "        \n",
    "#     end\n",
    "#     return nothing\n",
    "# end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads=(16,3)\n",
    "# @cuda(\n",
    "#     threads=threads,\n",
    "#     blocks=(cld.(size(agg.Position,1)+1,threads[1]),1),\n",
    "#     sum_force!(agg.Simulation.Neighbor.idx_red,agg.Simulation.Neighbor.idx_cont,agg.Simulation.Neighbor.idx_sum,agg.Position,agg.Simulation.Force.F,agg.Simulation.Parameter.Force,agg.Simulation.Parameter.Contractile.fₚ,model.Time.dt,1,agg.Simulation.Force.Pol)\n",
    "# )\n",
    "# display(agg.Simulation.Force.Pol)\n",
    "# display(agg.Position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_CPU          = Matrix(FusionAGG.Position)\n",
    "# idx_red_CPU    = Matrix(FusionAGG.Simulation.Neighbor.idx_red)\n",
    "# idx_cont_CPU   = Matrix(FusionAGG.Simulation.Neighbor.idx_cont)\n",
    "# force_CPU      = zeros(size(X_CPU))\n",
    "\n",
    "# Param = vcat(\n",
    "#         [\n",
    "#             unique(\n",
    "#                 getfield(FusionAGG.Simulation.Parameter.Force, fieldnames(Cubic)[i])\n",
    "#             ) for i=1:size(fieldnames(Cubic),1)\n",
    "#     ]...)\n",
    "# Param          = Cubic(Param...)\n",
    "# A_con          = unique(FusionAGG.Simulation.Parameter.Contractile.fₚ)[1]\n",
    "\n",
    "# t_knn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function runCPU()\n",
    "#     for j = 1:size(idx_red_CPU,1)\n",
    "#         for i =1:size(X_CPU,1)\n",
    "#             if idx_red_CPU[j,i] != 0 && idx_red_CPU[j,i] != i\n",
    "#                 dist = euclidean(X_CPU,i,idx_red_CPU[j,i])\n",
    "#                 force_CPU[i,:] += force_func(Param,dist) .* (X_CPU[i,:] - X_CPU[idx_red_CPU[j,i],:]) ./ dist\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "\n",
    "#     for i =1:size(X_CPU,1)\n",
    "#         if idx_cont_CPU[t_knn,i] != i\n",
    "#             dist = euclidean(X_CPU,i,idx_cont_CPU[t_knn,i])\n",
    "#             force_CPU[i,:] += A_con .* (X_CPU[i,:] - X_CPU[idx_cont_CPU[t_knn,i],:]) ./ dist\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# runCPU()\n",
    "# display(force_CPU)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Test\n",
    "# @test Matrix(FusionAGG.Simulation.Force.F) ≈ force_CPU atol=0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
