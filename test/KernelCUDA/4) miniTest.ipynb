{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunFusionAggregates (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../../src/struct_data.jl\")\n",
    "include(\"../../src/neighbor.jl\")\n",
    "include(\"../../src/forces/forces.jl\")\n",
    "include(\"../../src/run_event.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000009 seconds (5 allocations: 208 bytes)\n",
      "ModelSet\n",
      "  Time: TimeModel\n",
      "    tₛᵢₘ: Float64 100000.0\n",
      "    dt: Float64 0.5\n",
      "    nₖₙₙ: Int64 100\n",
      "    nₛₐᵥₑ: Int64 50\n",
      "  Input: InputModel\n",
      "    outer_ratio: Float64 0.8\n",
      "    path_input: String \"../../data/init/Sphere\"\n",
      "  Output: OutputModel\n",
      "    name_output: String \"Test_4_MiniTest\"\n",
      "    path_output: String \"\"\n"
     ]
    }
   ],
   "source": [
    "@time model = ModelSet(\n",
    "    TimeModel(\n",
    "        tₛᵢₘ  = 100000.0,\n",
    "        dt    = 0.5,\n",
    "        nₖₙₙ  = 100,\n",
    "        nₛₐᵥₑ = 50\n",
    "    ),\n",
    "    InputModel(\n",
    "        outer_ratio = 0.8,\n",
    "        path_input  = \"../../data/init/Sphere\"\n",
    "    ),\n",
    "    OutputModel(\n",
    "        name_output = \"Test_4_MiniTest\",\n",
    "        path_output = \"\"\n",
    "    ) \n",
    ")\n",
    "\n",
    "dump(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Par1 = Cubic(0.001,2.0,3.0)\n",
    "Par2 = ContractilePar(0.001)\n",
    "agg_size = 15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggregate(AggType[AggType(\"HEK_1\", InteractionPar(Cubic{Float64}(0.001, 2.0, 3.0), ContractilePar(0.001)), 15.27f0, Float32[-1.5 -4.62 -13.88; 0.5 -4.62 -13.88; … ; 0.5 4.62 13.88; 2.5 4.62 13.88], CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})], AggIndex([1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [\"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\"  …  \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\", \"HEK_1\"]), Float32[-1.5 -4.62 -13.88; 0.5 -4.62 -13.88; … ; 0.5 4.62 13.88; 2.5 4.62 13.88], AggGeometry(Float32[15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27  …  15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27, 15.27], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), AggSimulation(AggParameter(Cubic{CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}(Float32[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001  …  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001], Float32[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0  …  2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], Float32[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0  …  3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]), ContractilePar(Float32[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001  …  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]), Float32[15.27]), AggNeighbor(Int32[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Int32[0 0 … 0 0], Int32[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), AggForce(Float32[0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], Float32[0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], Float32[0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0])))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run only one aggregate\n",
    "agg = nothing\n",
    "agg = Aggregate(\n",
    "    [AggType(\n",
    "        \"HEK_1\", \n",
    "        InteractionPar(Par1, Par2),\n",
    "        Float32.(readdlm(\"../../data/init/Sphere/$(agg_size).0.xyz\")[3:end,2:end]) |> cu\n",
    "    )], \n",
    "    [AggLocation(\"HEK_1\",[0 0 0]),],\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run fusion of two aggregates\n",
    "# agg = nothing\n",
    "# agg = FusionAggregate(\n",
    "#     [AggType(\n",
    "#         \"HEK_1\", \n",
    "#         InteractionPar(Par1, Par2),\n",
    "#         Float32.(readdlm(\"../../data/init/Sphere/$(agg_size).0.xyz\")[3:end,2:end]) |> cu\n",
    "#     )], \n",
    "#     model\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2504 CuArray{Int32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 9  10  9  9  11  12  12  10  9  12  …  12  10  9  11  12  12  10  9  10  9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1000×2504 CuArray{Int32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 36  37  38  41  42  43  44  45  57  …  2461  2462  2463  2468  2469  2470\n",
       "  6   7   8  49   1   2   3   3  58     2502  2503  2504  2498  2499  2500\n",
       "  5   6   7  50  50   1   2  53  15     2503  2504  2455  2499  2500  2501\n",
       " 42  43  44   5  51  51  52  54  10     2454  2455  2456  2461  2462  2463\n",
       " 43  44  45  10   6  52  53   7  49     2453  2454  2500  2460  2461  2462\n",
       "  2   3   2   9   4   7   8  14   4  …  2498  2499  2495  2503  2502  2503\n",
       " 35   1  37  40  11   5   6  13  66     2500  2501  2496  2469  2504  2471\n",
       " 37  36  39  42  10  12  13  44  50     2493  2494  2462  2467  2468  2469\n",
       " 51  38  53  58  41  11  12  46  48     2494  2495  2464  2453  2470  2455\n",
       "  0  52   0   0  43  42  43  62   0     2460  2461  2447     0  2454     0\n",
       "  0   0   0   0  59  44  45   0   0  …  2462  2463     0     0     0     0\n",
       "  0   0   0   0   0  60  61   0   0     2445  2446     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  ⋮                   ⋮              ⋱                 ⋮              \n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0  …     0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0  …     0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0\n",
       "  0   0   0   0   0   0   0   0   0        0     0     0     0     0     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = zeros(size(agg.Simulation.Neighbor.idx_red)) |> cu\n",
    "threads=(100)\n",
    "@cuda(\n",
    "    threads=threads,\n",
    "    blocks=cld.(size(agg.Position,1),threads),\n",
    "    dist_kernel!(\n",
    "        agg.Simulation.Neighbor.idx_red,\n",
    "        agg.Simulation.Neighbor.idx_cont,\n",
    "        agg.Simulation.Neighbor.idx_sum,\n",
    "        dist,\n",
    "        agg.Position,\n",
    "        agg.Simulation.Parameter.Force.rₘₐₓ\n",
    "    )\n",
    ")   \n",
    "display(agg.Simulation.Neighbor.idx_sum)\n",
    "display(agg.Simulation.Neighbor.idx_red)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum Forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.493938 seconds (2.62 M CPU allocations: 172.527 MiB, 3.51% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2504×3 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -0.000626234  -0.00467133   -0.00277445\n",
       "  0.0034037    -0.00222225   -0.00310171\n",
       "  0.00372308   -3.55103f-5   -0.00187945\n",
       "  0.00133489    0.000822262  -0.00473754\n",
       "  0.00485888   -0.00156919   -0.00313317\n",
       " -0.00262288    0.000897761   0.00534295\n",
       "  0.00137278    0.00511903    0.00191356\n",
       " -0.0017857     0.00552607   -0.00236329\n",
       " -0.00215859    0.00139921    0.00292971\n",
       " -0.00442171    0.00153486   -0.00562478\n",
       " -0.00580766    0.0016181    -0.00319354\n",
       " -0.00382257    0.00447777    0.000245941\n",
       " -0.000989015  -0.00573164   -0.00231611\n",
       "  ⋮                          \n",
       " -0.00357179   -0.00220504   -0.00222989\n",
       " -0.00161082    0.00553813    0.00169546\n",
       "  0.00609809    0.00259497    0.00189687\n",
       " -0.000375798   0.00503645    0.00130884\n",
       " -0.00174308    0.00167925    0.0053075\n",
       "  0.00290555    0.00412411    0.00480808\n",
       "  0.00590847    0.0010034    -0.00156365\n",
       " -0.00144504    0.00622333    0.00265817\n",
       "  0.000175885  -0.00385496    0.00457723\n",
       " -0.00246103    0.003248      0.00449317\n",
       " -0.00204269   -0.00176825    0.00577645\n",
       " -0.0027264     0.00386239    0.00182423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2504×3 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " -1.50031   -4.62234  -13.8814\n",
       "  0.501702  -4.62111  -13.8816\n",
       "  2.50186   -4.62002  -13.8809\n",
       " -4.49933   -2.88959  -13.8824\n",
       " -2.49757   -2.89078  -13.8816\n",
       " -0.501311  -2.88955  -13.8773\n",
       "  1.50069   -2.88744  -13.879\n",
       "  3.49911   -2.88724  -13.8812\n",
       " -5.50108   -1.1493   -13.8785\n",
       " -3.50221   -1.14923  -13.8828\n",
       " -1.5029    -1.14919  -13.8816\n",
       "  0.498089  -1.14776  -13.8799\n",
       "  2.49951   -1.15287  -13.8812\n",
       "  ⋮                   \n",
       " -1.50179    1.1489    13.8789\n",
       "  0.499195   1.15277   13.8808\n",
       "  2.50305    1.1513    13.8809\n",
       "  4.49981    1.15252   13.8807\n",
       " -4.50087    2.89084   13.8827\n",
       " -2.49855    2.89206   13.8824\n",
       " -0.497046   2.8905    13.8792\n",
       "  1.49928    2.89311   13.8813\n",
       "  3.50009    2.88807   13.8823\n",
       " -1.50123    4.62162   13.8822\n",
       "  0.498979   4.61912   13.8829\n",
       "  2.49864    4.62193   13.8809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threads=(64,3)\n",
    "CUDA.@time @cuda(\n",
    "    threads = threads,\n",
    "    blocks = cld.(size(agg.Position,),threads),\n",
    "    shmem=prod(threads.+2)*sizeof(Float32),\n",
    "    sum_force!(\n",
    "        agg.Position,\n",
    "        agg.Simulation.Force.F,\n",
    "        agg.Simulation.Force.Pol,\n",
    "        agg.Simulation.Neighbor.idx_sum,\n",
    "        agg.Simulation.Neighbor.idx_red,\n",
    "        agg.Simulation.Parameter.Force,\n",
    "        agg.Simulation.Parameter.Contractile.fₚ,\n",
    "        atan(0.1),\n",
    "        pi/3,\n",
    "        model.Time.dt\n",
    "    )\n",
    ")\n",
    "\n",
    "display(agg.Simulation.Force.F)\n",
    "display(agg.Position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mmini Testing...   0%|▏                                   |  ETA: 0:00:41\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: a exception was thrown during kernel execution.\n",
      "       Run Julia on debug level 2 for device stack traces.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "CUDA error: an illegal instruction was encountered (code 715, ERROR_ILLEGAL_INSTRUCTION)",
     "output_type": "error",
     "traceback": [
      "CUDA error: an illegal instruction was encountered (code 715, ERROR_ILLEGAL_INSTRUCTION)",
      "",
      "Stacktrace:",
      "  [1] throw_api_error(res::CUDA.cudaError_enum)",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/libcuda.jl:27",
      "  [2] check",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/libcuda.jl:34 [inlined]",
      "  [3] cuLaunchKernel",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/utils/call.jl:26 [inlined]",
      "  [4] (::CUDA.var\"#863#864\"{Bool, Int64, CuStream, CuFunction, CuDim3, CuDim3})(kernelParams::Vector{Ptr{Nothing}})",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:69",
      "  [5] macro expansion",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:33 [inlined]",
      "  [6] macro expansion",
      "    @ ./none:0 [inlined]",
      "  [7] pack_arguments(::CUDA.var\"#863#864\"{Bool, Int64, CuStream, CuFunction, CuDim3, CuDim3}, ::CUDA.KernelState, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Int32, 1}, ::CuDeviceMatrix{Int32, 1}, ::Cubic{CuDeviceVector{Float32, 1}}, ::CuDeviceVector{Float32, 1}, ::Float64, ::Float64, ::Float64)",
      "    @ CUDA ./none:0",
      "  [8] #launch#862",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:62 [inlined]",
      "  [9] #868",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:136 [inlined]",
      " [10] macro expansion",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:95 [inlined]",
      " [11] macro expansion",
      "    @ ./none:0 [inlined]",
      " [12] convert_arguments",
      "    @ ./none:0 [inlined]",
      " [13] #cudacall#867",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:135 [inlined]",
      " [14] cudacall",
      "    @ ~/.julia/packages/CUDA/pCcGc/lib/cudadrv/execution.jl:134 [inlined]",
      " [15] macro expansion",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:219 [inlined]",
      " [16] macro expansion",
      "    @ ./none:0 [inlined]",
      " [17] call(::CUDA.HostKernel{typeof(sum_force!), Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Int32, 1}, CuDeviceMatrix{Int32, 1}, Cubic{CuDeviceVector{Float32, 1}}, CuDeviceVector{Float32, 1}, Float64, Float64, Float64}}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Float32, 1}, ::CuDeviceMatrix{Int32, 1}, ::CuDeviceMatrix{Int32, 1}, ::Cubic{CuDeviceVector{Float32, 1}}, ::CuDeviceVector{Float32, 1}, ::Float64, ::Float64, ::Float64; call_kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:threads, :blocks, :shmem), Tuple{Tuple{Int64, Int64}, Tuple{Int64, Int64}, Int64}}})",
      "    @ CUDA ./none:0",
      " [18] (::CUDA.HostKernel{typeof(sum_force!), Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Float32, 1}, CuDeviceMatrix{Int32, 1}, CuDeviceMatrix{Int32, 1}, Cubic{CuDeviceVector{Float32, 1}}, CuDeviceVector{Float32, 1}, Float64, Float64, Float64}})(::CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, ::Vararg{Any}; threads::Tuple{Int64, Int64}, blocks::Tuple{Int64, Int64}, kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:shmem,), Tuple{Int64}}})",
      "    @ CUDA ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:340",
      " [19] macro expansion",
      "    @ ~/.julia/packages/CUDA/pCcGc/src/compiler/execution.jl:106 [inlined]",
      " [20] macro expansion",
      "    @ ~/Documentos/MaestriaUNAL/CellAggregate.jl/src/run_event.jl:15 [inlined]",
      " [21] macro expansion",
      "    @ ~/.julia/packages/ProgressMeter/sN2xr/src/ProgressMeter.jl:938 [inlined]",
      " [22] run_test(agg::Aggregate, model::ModelSet, title::String)",
      "    @ Main ~/Documentos/MaestriaUNAL/CellAggregate.jl/src/run_event.jl:11",
      " [23] top-level scope",
      "    @ In[9]:1"
     ]
    }
   ],
   "source": [
    "run_test(agg, model, \"mini Testing\")\n",
    "display(sum(isnan.(agg.Simulation.Force.F), dims=1))\n",
    "display(sum(agg.Simulation.Force.F .> 50, dims=1))\n",
    "display(agg.Simulation.Force.F)\n",
    "display(agg.Position)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
