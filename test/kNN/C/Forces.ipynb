{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9db0f1-6e48-4b16-9dc7-ff66dd10d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "using CUDA\n",
    "using BenchmarkTools\n",
    "using CUDA.CUSPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a118b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_Agg = 15\n",
    "r_max = 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65556d80-fba2-45fb-b40e-39ff7694ad0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inizializating Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a482bce8-f0cb-4c1b-90fc-35e5540870ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Float64.(readdlm(\"../../../data/init/Sphere/$R_Agg.xyz\")[3:end,2:end]) |> cu\n",
    "\n",
    "forces  = CUDA.zeros(size(X, 1), size(X, 1),3)\n",
    "idx     = CUDA.zeros(size(X, 1), size(X, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5076e59-c535-42a4-89c0-a11450c2a6ac",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b535c620-c4e0-4911-b362-ab1862c63ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "force_kernel! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cuda_distance_kernel!(idx, points ,r_max)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    j = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "\n",
    "    if i <= size(points, 1) && j <= size(points, 1)\n",
    "        d = sqrt(\n",
    "            (points[i,1] - points[j,1])^2 + \n",
    "            (points[i,2] - points[j,2])^2 + \n",
    "            (points[i,3] - points[j,3])^2\n",
    "            )\n",
    "        if d < r_max\n",
    "            idx[i, j] = 1\n",
    "        end \n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "FAFA(x) = 1.0\n",
    "function force_kernel!(points, idx, force)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    j = (blockIdx().y - 1) * blockDim().y + threadIdx().y\n",
    "\n",
    "    if i <= size(idx, 1) && j <= size(idx, 2) \n",
    "        if idx[i,j] == 0 || i == j\n",
    "            force[i,j,1] = force[i,j,2] = force[i,j,3] = 0\n",
    "        else\n",
    "            d = sqrt(\n",
    "                        (points[i,1] - points[j,1])^2 + \n",
    "                        (points[i,2] - points[j,2])^2 + \n",
    "                        (points[i,3] - points[j,3])^2\n",
    "                )\n",
    "            for k in 1:3\n",
    "                force[i,j,k] = FAFA(d) * points[i,k] / d\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96354aa-ccad-4fe8-85ba-094938d41c50",
   "metadata": {},
   "source": [
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e50ec9a-d590-4712-b1c1-b52ea1d92831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.706067 seconds (24.81 M CPU allocations: 1.417 GiB, 4.10% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2504×2504 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 1.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱                 ⋮              \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  1.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  1.0  1.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  1.0  1.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  1.0  1.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  0.0  0.0  1.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  1.0  0.0  1.0  1.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  1.0  1.0  0.0  1.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  1.0  0.0  1.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  1.0  1.0  0.0  1.0  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads = (32, 32)\n",
    "blocks = (div(size(X,1),threads[1])+1, div(size(X,1),threads[1])+1)\n",
    "\n",
    "CUDA.@time @cuda threads=threads blocks=blocks cuda_distance_kernel!(idx, X, r_max)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5325e64-3f1b-4da2-9b44-8db9727de61b",
   "metadata": {},
   "source": [
    "# Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fa34b8-8aaa-4755-96a5-3e8eb89590b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.630760 seconds (2.39 M CPU allocations: 137.252 MiB, 6.57% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2504×2504×3 CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}:\n",
       "[:, :, 1] =\n",
       "  0.0       -0.75       0.0       …   0.0        0.0        0.0\n",
       "  0.25       0.0        0.25          0.0        0.0        0.0\n",
       "  0.0        1.25       0.0           0.0        0.0        0.0\n",
       " -1.29942    0.0        0.0           0.0        0.0        0.0\n",
       " -1.25111   -0.721901   0.0           0.0        0.0        0.0\n",
       " -0.250222  -0.250222  -0.14438   …   0.0        0.0        0.0\n",
       "  0.433141   0.750667   0.750667      0.0        0.0        0.0\n",
       "  0.0        1.01066    1.75156       0.0        0.0        0.0\n",
       "  0.0        0.0        0.0           0.0        0.0        0.0\n",
       "  0.0        0.0        0.0           0.0        0.0        0.0\n",
       " -0.432277   0.0        0.0       …   0.0        0.0        0.0\n",
       "  0.0        0.144092   0.0           0.0        0.0        0.0\n",
       "  0.0        0.0        0.720461      0.0        0.0        0.0\n",
       "  ⋮                               ⋱                        \n",
       "  0.0        0.0        0.0          -0.432277   0.0        0.0\n",
       "  0.0        0.0        0.0           0.0        0.144092   0.0\n",
       "  0.0        0.0        0.0           0.0        0.0        0.720461\n",
       "  0.0        0.0        0.0       …   0.0        0.0        0.0\n",
       "  0.0        0.0        0.0          -1.29942    0.0        0.0\n",
       "  0.0        0.0        0.0          -1.25111   -0.721901   0.0\n",
       "  0.0        0.0        0.0          -0.250222  -0.250222  -0.14438\n",
       "  0.0        0.0        0.0           0.433141   0.750667   0.750667\n",
       "  0.0        0.0        0.0       …   0.0        1.01066    1.75156\n",
       "  0.0        0.0        0.0           0.0       -0.75       0.0\n",
       "  0.0        0.0        0.0           0.25       0.0        0.25\n",
       "  0.0        0.0        0.0           0.0        1.25       0.0\n",
       "\n",
       "[:, :, 2] =\n",
       "  0.0       -2.31       0.0       -1.33407   …  0.0       0.0       0.0\n",
       " -2.31       0.0       -2.31       0.0          0.0       0.0       0.0\n",
       "  0.0       -2.31       0.0        0.0          0.0       0.0       0.0\n",
       " -0.834518   0.0        0.0        0.0          0.0       0.0       0.0\n",
       " -1.44628   -0.834518   0.0       -1.445        0.0       0.0       0.0\n",
       " -1.44628   -1.44628   -0.834518   0.0       …  0.0       0.0       0.0\n",
       " -0.834518  -1.44628   -1.44628    0.0          0.0       0.0       0.0\n",
       "  0.0       -0.834518  -1.44628    0.0          0.0       0.0       0.0\n",
       "  0.0        0.0        0.0       -0.573026     0.0       0.0       0.0\n",
       "  0.0        0.0        0.0       -0.573026     0.0       0.0       0.0\n",
       " -0.331412   0.0        0.0       -0.331595  …  0.0       0.0       0.0\n",
       "  0.0       -0.331412   0.0        0.0          0.0       0.0       0.0\n",
       "  0.0        0.0       -0.331412   0.0          0.0       0.0       0.0\n",
       "  ⋮                                          ⋱                      \n",
       "  0.0        0.0        0.0        0.0          0.331412  0.0       0.0\n",
       "  0.0        0.0        0.0        0.0          0.0       0.331412  0.0\n",
       "  0.0        0.0        0.0        0.0          0.0       0.0       0.331412\n",
       "  0.0        0.0        0.0        0.0       …  0.0       0.0       0.0\n",
       "  0.0        0.0        0.0        0.0          0.834518  0.0       0.0\n",
       "  0.0        0.0        0.0        0.0          1.44628   0.834518  0.0\n",
       "  0.0        0.0        0.0        0.0          1.44628   1.44628   0.834518\n",
       "  0.0        0.0        0.0        0.0          0.834518  1.44628   1.44628\n",
       "  0.0        0.0        0.0        0.0       …  0.0       0.834518  1.44628\n",
       "  0.0        0.0        0.0        0.0          0.0       2.31      0.0\n",
       "  0.0        0.0        0.0        0.0          2.31      0.0       2.31\n",
       "  0.0        0.0        0.0        0.0          0.0       2.31      0.0\n",
       "\n",
       "[:, :, 3] =\n",
       "  0.0      -6.94      0.0      …  0.0      0.0      0.0      0.0\n",
       " -6.94      0.0      -6.94        0.0      0.0      0.0      0.0\n",
       "  0.0      -6.94      0.0         0.0      0.0      0.0      0.0\n",
       " -4.008     0.0       0.0         0.0      0.0      0.0      0.0\n",
       " -6.94617  -4.008     0.0         0.0      0.0      0.0      0.0\n",
       " -6.94617  -6.94617  -4.008    …  0.0      0.0      0.0      0.0\n",
       " -4.008    -6.94617  -6.94617     0.0      0.0      0.0      0.0\n",
       "  0.0      -4.008    -6.94617     0.0      0.0      0.0      0.0\n",
       "  0.0       0.0       0.0         0.0      0.0      0.0      0.0\n",
       "  0.0       0.0       0.0         0.0      0.0      0.0      0.0\n",
       " -4.0       0.0       0.0      …  0.0      0.0      0.0      0.0\n",
       "  0.0      -4.0       0.0         0.0      0.0      0.0      0.0\n",
       "  0.0       0.0      -4.0         0.0      0.0      0.0      0.0\n",
       "  ⋮                            ⋱  ⋮                          \n",
       "  0.0       0.0       0.0         0.0      4.0      0.0      0.0\n",
       "  0.0       0.0       0.0         4.00221  0.0      4.0      0.0\n",
       "  0.0       0.0       0.0         6.91618  0.0      0.0      4.0\n",
       "  0.0       0.0       0.0      …  6.91618  0.0      0.0      0.0\n",
       "  0.0       0.0       0.0         0.0      4.008    0.0      0.0\n",
       "  0.0       0.0       0.0         0.0      6.94617  4.008    0.0\n",
       "  0.0       0.0       0.0         0.0      6.94617  6.94617  4.008\n",
       "  0.0       0.0       0.0         6.94     4.008    6.94617  6.94617\n",
       "  0.0       0.0       0.0      …  0.0      0.0      4.008    6.94617\n",
       "  0.0       0.0       0.0         0.0      0.0      6.94     0.0\n",
       "  0.0       0.0       0.0         4.008    6.94     0.0      6.94\n",
       "  0.0       0.0       0.0         6.94617  0.0      6.94     0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads = (32, 32)\n",
    "blocks = (div(size(X,1),threads[1])+1, div(size(X,1),threads[1])+1)\n",
    "\n",
    "CUDA.@time @cuda threads=threads blocks=blocks force_kernel!(X, idx, forces)\n",
    "forces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7eb1d-b190-49a9-89c5-c297830c8d35",
   "metadata": {},
   "source": [
    "# Distances v2.0 with reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ca79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.84128    0.743069  0.0481819  0.247759\n",
       " 0.0851737  0.703345  0.777963   0.217134\n",
       " 0.529234   0.735049  0.0727251  0.3483\n",
       " 0.0508005  0.701725  0.949826   0.261283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "A = CUDA.zeros(N, N)\n",
    "Q = CUDA.rand(N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d476b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum_columns_kernel! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "function sum_columns_kernel!(A, B)\n",
    "    # get the index of the current thread\n",
    "    i = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
    "\n",
    "    # load the chunk of matrix A into shared memory\n",
    "    chunk_size = 32\n",
    "    num_chunks = div(size(A, 1) - 1, chunk_size) + 1\n",
    "    shared_A = cuDynamicSharedMem(Float32, chunk_size, size(A, 2))\n",
    "    for c = 1:num_chunks\n",
    "        if (c - 1) * chunk_size + threadIdx().y <= size(A, 1)\n",
    "            shared_A[threadIdx().y, threadIdx().x + (c - 1) * chunk_size] = A[(c - 1) * chunk_size + threadIdx().y, i]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # synchronize all threads in the block\n",
    "    sync_threads()\n",
    "\n",
    "    # sum the values in the i-th column of A in shared memory\n",
    "    col_sum = 0.0\n",
    "    for j = 1:chunk_size:size(A, 1)\n",
    "        if j + threadIdx().y <= size(A, 1) && threadIdx().x <= size(A, 2)\n",
    "            col_sum += shared_A[threadIdx().y, threadIdx().x]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # store the sum in the i-th element of B\n",
    "    B[i] = col_sum\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23406c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×100 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.438724     0.189343   0.627552    …  0.52686    0.155131     0.290198\n",
       " 0.912573     0.612472   0.968097       0.522831   0.247001     0.921432\n",
       " 0.896611     0.998586   0.879535       0.882677   0.114865     0.12126\n",
       " 0.000344162  0.234257   0.0870909      0.974042   0.661214     0.125305\n",
       " 0.526385     0.669496   0.00367098     0.801127   0.124747     0.458054\n",
       " 0.920148     0.608125   0.694353    …  0.625559   0.450203     0.267145\n",
       " 0.592351     0.668379   0.322444       0.848898   0.103777     0.645337\n",
       " 0.592244     0.875131   0.69188        0.501523   0.518926     0.780971\n",
       " 0.970679     0.79105    0.62458        0.364136   0.492364     0.246441\n",
       " 0.816516     0.0254132  0.10845        0.543397   0.337961     0.165916\n",
       " 0.728507     0.963514   0.53891     …  0.903866   0.886301     0.200495\n",
       " 0.13424      0.339632   0.359327       0.81907    0.464102     0.655418\n",
       " 0.384954     0.755138   0.271422       0.481319   0.445525     0.102457\n",
       " ⋮                                   ⋱                          \n",
       " 0.993453     0.549391   0.477577       0.792791   0.202665     0.737723\n",
       " 0.749431     0.921379   0.0411392      0.938223   0.723121     0.304728\n",
       " 0.213386     0.103371   0.381482    …  0.186979   0.0148604    0.497867\n",
       " 0.836349     0.25738    0.553689       0.935165   0.792215     0.288632\n",
       " 0.150147     0.179372   0.558325       0.37411    0.129222     0.462691\n",
       " 0.116839     0.143397   0.501326       0.864718   0.493909     0.525842\n",
       " 0.815771     0.95276    0.92018        0.115266   0.306323     0.618534\n",
       " 0.262612     0.704213   0.98488     …  0.505294   0.438179     0.557924\n",
       " 0.213512     0.394404   0.875597       0.266426   0.000930013  0.823185\n",
       " 0.0299006    0.0196293  0.652748       0.49986    0.487207     0.110359\n",
       " 0.438201     0.0170148  0.508949       0.0986658  0.221908     0.229582\n",
       " 0.311989     0.553148   0.507881       0.600627   0.222146     0.0227287"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "B = CUDA.zeros(N)\n",
    "A = CUDA.rand(N,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b6f9be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InvalidIRError: compiling kernel #sum_columns_kernel!(CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}) resulted in invalid LLVM IR\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to setindex!)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:13\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to getindex)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:24\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to +)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:24\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to convert)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msetindex!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m~/.julia/packages/CUDA/DfvRa/src/device/\u001b[39m\u001b[90;4marray.jl:194\u001b[0m\n [2] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:29\u001b[0m\n\u001b[31mReason: unsupported use of an undefined name\u001b[39m\u001b[31m (use of 'cuDynamicSharedMem')\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:10\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:10\u001b[0m\n\u001b[36m\u001b[1mHint\u001b[22m\u001b[39m\u001b[36m: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl\u001b[39m",
     "output_type": "error",
     "traceback": [
      "InvalidIRError: compiling kernel #sum_columns_kernel!(CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}) resulted in invalid LLVM IR\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to setindex!)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:13\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to getindex)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:24\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to +)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:24\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\u001b[31m (call to convert)\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msetindex!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m~/.julia/packages/CUDA/DfvRa/src/device/\u001b[39m\u001b[90;4marray.jl:194\u001b[0m\n [2] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:29\u001b[0m\n\u001b[31mReason: unsupported use of an undefined name\u001b[39m\u001b[31m (use of 'cuDynamicSharedMem')\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:10\u001b[0m\n\u001b[31mReason: unsupported dynamic function invocation\u001b[39m\nStacktrace:\n [1] \u001b[0m\u001b[1msum_columns_kernel!\u001b[22m\n\u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[10]:10\u001b[0m\n\u001b[36m\u001b[1mHint\u001b[22m\u001b[39m\u001b[36m: catch this exception as `err` and call `code_typed(err; interactive = true)` to introspect the erronous code with Cthulhu.jl\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] check_ir(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams, GPUCompiler.FunctionSpec{typeof(sum_columns_kernel!), Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}}}}, args::LLVM.Module)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/07qaN/src/validation.jl:141",
      "  [2] macro expansion",
      "    @ ~/.julia/packages/GPUCompiler/07qaN/src/driver.jl:418 [inlined]",
      "  [3] macro expansion",
      "    @ ~/.julia/packages/TimerOutputs/4yHI4/src/TimerOutput.jl:253 [inlined]",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/GPUCompiler/07qaN/src/driver.jl:416 [inlined]",
      "  [5] emit_asm(job::GPUCompiler.CompilerJob, ir::LLVM.Module; strip::Bool, validate::Bool, format::LLVM.API.LLVMCodeGenFileType)",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/07qaN/src/utils.jl:68",
      "  [6] cufunction_compile(job::GPUCompiler.CompilerJob, ctx::LLVM.Context)",
      "    @ CUDA ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:354",
      "  [7] #222",
      "    @ ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:347 [inlined]",
      "  [8] JuliaContext(f::CUDA.var\"#222#223\"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget, CUDA.CUDACompilerParams, GPUCompiler.FunctionSpec{typeof(sum_columns_kernel!), Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}}}}})",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/07qaN/src/driver.jl:76",
      "  [9] cufunction_compile(job::GPUCompiler.CompilerJob)",
      "    @ CUDA ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:346",
      " [10] cached_compilation(cache::Dict{UInt64, Any}, job::GPUCompiler.CompilerJob, compiler::typeof(CUDA.cufunction_compile), linker::typeof(CUDA.cufunction_link))",
      "    @ GPUCompiler ~/.julia/packages/GPUCompiler/07qaN/src/cache.jl:90",
      " [11] cufunction(f::typeof(sum_columns_kernel!), tt::Type{Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ CUDA ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:299",
      " [12] cufunction(f::typeof(sum_columns_kernel!), tt::Type{Tuple{CuDeviceMatrix{Float32, 1}, CuDeviceVector{Float32, 1}}})",
      "    @ CUDA ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:293",
      " [13] macro expansion",
      "    @ ~/.julia/packages/CUDA/DfvRa/src/compiler/execution.jl:102 [inlined]",
      " [14] macro expansion",
      "    @ ~/.julia/packages/CUDA/DfvRa/src/utilities.jl:25 [inlined]",
      " [15] top-level scope",
      "    @ ~/.julia/packages/CUDA/DfvRa/src/pool.jl:490 [inlined]",
      " [16] top-level scope",
      "    @ ./In[12]:0",
      " [17] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [18] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# launch the kernel with 3 threads (one for each column)\n",
    "CUDA.@time @cuda threads=1024 sum_columns_kernel!(A, B)\n",
    "B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
